{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in /opt/conda/lib/python3.12/site-packages (25.1.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: tensorflow==2.18.0 in /opt/conda/lib/python3.12/site-packages (2.18.0)\n",
      "Requirement already satisfied: keras==3.9.0 in /opt/conda/lib/python3.12/site-packages (3.9.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /opt/conda/lib/python3.12/site-packages (from tensorflow==2.18.0) (2.2.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /opt/conda/lib/python3.12/site-packages (from tensorflow==2.18.0) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in /opt/conda/lib/python3.12/site-packages (from tensorflow==2.18.0) (25.2.10)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /opt/conda/lib/python3.12/site-packages (from tensorflow==2.18.0) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /opt/conda/lib/python3.12/site-packages (from tensorflow==2.18.0) (0.2.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /opt/conda/lib/python3.12/site-packages (from tensorflow==2.18.0) (3.4.0)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.12/site-packages (from tensorflow==2.18.0) (24.2)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /opt/conda/lib/python3.12/site-packages (from tensorflow==2.18.0) (5.28.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.12/site-packages (from tensorflow==2.18.0) (2.32.3)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.12/site-packages (from tensorflow==2.18.0) (80.1.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.12/site-packages (from tensorflow==2.18.0) (1.17.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /opt/conda/lib/python3.12/site-packages (from tensorflow==2.18.0) (3.1.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /opt/conda/lib/python3.12/site-packages (from tensorflow==2.18.0) (4.13.2)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /opt/conda/lib/python3.12/site-packages (from tensorflow==2.18.0) (1.17.2)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /opt/conda/lib/python3.12/site-packages (from tensorflow==2.18.0) (1.67.1)\n",
      "Requirement already satisfied: tensorboard<2.19,>=2.18 in /opt/conda/lib/python3.12/site-packages (from tensorflow==2.18.0) (2.18.0)\n",
      "Requirement already satisfied: h5py>=3.11.0 in /opt/conda/lib/python3.12/site-packages (from tensorflow==2.18.0) (3.13.0)\n",
      "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /opt/conda/lib/python3.12/site-packages (from tensorflow==2.18.0) (0.4.0)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.12/site-packages (from keras==3.9.0) (1.26.4)\n",
      "Requirement already satisfied: rich in /opt/conda/lib/python3.12/site-packages (from keras==3.9.0) (13.9.4)\n",
      "Requirement already satisfied: namex in /opt/conda/lib/python3.12/site-packages (from keras==3.9.0) (0.0.9)\n",
      "Requirement already satisfied: optree in /opt/conda/lib/python3.12/site-packages (from keras==3.9.0) (0.15.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/conda/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow==2.18.0) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow==2.18.0) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow==2.18.0) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow==2.18.0) (2025.1.31)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.12/site-packages (from tensorboard<2.19,>=2.18->tensorflow==2.18.0) (3.8)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/conda/lib/python3.12/site-packages (from tensorboard<2.19,>=2.18->tensorflow==2.18.0) (0.7.0)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.12/site-packages (from tensorboard<2.19,>=2.18->tensorflow==2.18.0) (3.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.12/site-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow==2.18.0) (3.0.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.12/site-packages (from rich->keras==3.9.0) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.12/site-packages (from rich->keras==3.9.0) (2.19.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.12/site-packages (from markdown-it-py>=2.2.0->rich->keras==3.9.0) (0.1.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: trl==0.5.0 in /opt/conda/lib/python3.12/site-packages (0.5.0)\n",
      "Requirement already satisfied: torch>=1.4.0 in /opt/conda/lib/python3.12/site-packages (from trl==0.5.0) (2.5.1)\n",
      "Requirement already satisfied: transformers>=4.18.0 in /opt/conda/lib/python3.12/site-packages (from trl==0.5.0) (4.38.2)\n",
      "Requirement already satisfied: numpy>=1.18.2 in /opt/conda/lib/python3.12/site-packages (from trl==0.5.0) (1.26.4)\n",
      "Requirement already satisfied: accelerate in /opt/conda/lib/python3.12/site-packages (from trl==0.5.0) (1.5.2)\n",
      "Requirement already satisfied: datasets in /opt/conda/lib/python3.12/site-packages (from trl==0.5.0) (2.17.0)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.12/site-packages (from torch>=1.4.0->trl==0.5.0) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.12/site-packages (from torch>=1.4.0->trl==0.5.0) (4.13.2)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.12/site-packages (from torch>=1.4.0->trl==0.5.0) (80.1.0)\n",
      "Requirement already satisfied: sympy!=1.13.2,>=1.13.1 in /opt/conda/lib/python3.12/site-packages (from torch>=1.4.0->trl==0.5.0) (1.14.0)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.12/site-packages (from torch>=1.4.0->trl==0.5.0) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.12/site-packages (from torch>=1.4.0->trl==0.5.0) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.12/site-packages (from torch>=1.4.0->trl==0.5.0) (2023.10.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.12/site-packages (from sympy!=1.13.2,>=1.13.1->torch>=1.4.0->trl==0.5.0) (1.3.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /opt/conda/lib/python3.12/site-packages (from transformers>=4.18.0->trl==0.5.0) (0.30.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.12/site-packages (from transformers>=4.18.0->trl==0.5.0) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.12/site-packages (from transformers>=4.18.0->trl==0.5.0) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.12/site-packages (from transformers>=4.18.0->trl==0.5.0) (2024.11.6)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.12/site-packages (from transformers>=4.18.0->trl==0.5.0) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in /opt/conda/lib/python3.12/site-packages (from transformers>=4.18.0->trl==0.5.0) (0.15.2)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.12/site-packages (from transformers>=4.18.0->trl==0.5.0) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.12/site-packages (from transformers>=4.18.0->trl==0.5.0) (4.67.1)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.12/site-packages (from accelerate->trl==0.5.0) (5.9.8)\n",
      "Requirement already satisfied: pyarrow>=12.0.0 in /opt/conda/lib/python3.12/site-packages (from datasets->trl==0.5.0) (19.0.1)\n",
      "Requirement already satisfied: pyarrow-hotfix in /opt/conda/lib/python3.12/site-packages (from datasets->trl==0.5.0) (0.7)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.12/site-packages (from datasets->trl==0.5.0) (0.3.8)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.12/site-packages (from datasets->trl==0.5.0) (2.2.3)\n",
      "Requirement already satisfied: xxhash in /opt/conda/lib/python3.12/site-packages (from datasets->trl==0.5.0) (3.5.0)\n",
      "Requirement already satisfied: multiprocess in /opt/conda/lib/python3.12/site-packages (from datasets->trl==0.5.0) (0.70.16)\n",
      "Requirement already satisfied: aiohttp in /opt/conda/lib/python3.12/site-packages (from datasets->trl==0.5.0) (3.9.5)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.12/site-packages (from aiohttp->datasets->trl==0.5.0) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.12/site-packages (from aiohttp->datasets->trl==0.5.0) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.12/site-packages (from aiohttp->datasets->trl==0.5.0) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.12/site-packages (from aiohttp->datasets->trl==0.5.0) (6.4.3)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.12/site-packages (from aiohttp->datasets->trl==0.5.0) (1.20.0)\n",
      "Requirement already satisfied: idna>=2.0 in /opt/conda/lib/python3.12/site-packages (from yarl<2.0,>=1.0->aiohttp->datasets->trl==0.5.0) (3.10)\n",
      "Requirement already satisfied: propcache>=0.2.1 in /opt/conda/lib/python3.12/site-packages (from yarl<2.0,>=1.0->aiohttp->datasets->trl==0.5.0) (0.3.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/conda/lib/python3.12/site-packages (from requests->transformers>=4.18.0->trl==0.5.0) (3.4.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.12/site-packages (from requests->transformers>=4.18.0->trl==0.5.0) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.12/site-packages (from requests->transformers>=4.18.0->trl==0.5.0) (2025.1.31)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.12/site-packages (from jinja2->torch>=1.4.0->trl==0.5.0) (3.0.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.12/site-packages (from pandas->datasets->trl==0.5.0) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.12/site-packages (from pandas->datasets->trl==0.5.0) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.12/site-packages (from pandas->datasets->trl==0.5.0) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas->datasets->trl==0.5.0) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: datasets==2.17.0 in /opt/conda/lib/python3.12/site-packages (2.17.0)\n",
      "Requirement already satisfied: transformers==4.38.2 in /opt/conda/lib/python3.12/site-packages (4.38.2)\n",
      "Requirement already satisfied: evaluate==0.4.0 in /opt/conda/lib/python3.12/site-packages (0.4.0)\n",
      "Requirement already satisfied: rouge_score==0.1.2 in /opt/conda/lib/python3.12/site-packages (0.1.2)\n",
      "Requirement already satisfied: peft==0.3.0 in /opt/conda/lib/python3.12/site-packages (0.3.0)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.12/site-packages (from datasets==2.17.0) (3.18.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.12/site-packages (from datasets==2.17.0) (1.26.4)\n",
      "Requirement already satisfied: pyarrow>=12.0.0 in /opt/conda/lib/python3.12/site-packages (from datasets==2.17.0) (19.0.1)\n",
      "Requirement already satisfied: pyarrow-hotfix in /opt/conda/lib/python3.12/site-packages (from datasets==2.17.0) (0.7)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.12/site-packages (from datasets==2.17.0) (0.3.8)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.12/site-packages (from datasets==2.17.0) (2.2.3)\n",
      "Requirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.12/site-packages (from datasets==2.17.0) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.12/site-packages (from datasets==2.17.0) (4.67.1)\n",
      "Requirement already satisfied: xxhash in /opt/conda/lib/python3.12/site-packages (from datasets==2.17.0) (3.5.0)\n",
      "Requirement already satisfied: multiprocess in /opt/conda/lib/python3.12/site-packages (from datasets==2.17.0) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2023.10.0,>=2023.1.0 in /opt/conda/lib/python3.12/site-packages (from fsspec[http]<=2023.10.0,>=2023.1.0->datasets==2.17.0) (2023.10.0)\n",
      "Requirement already satisfied: aiohttp in /opt/conda/lib/python3.12/site-packages (from datasets==2.17.0) (3.9.5)\n",
      "Requirement already satisfied: huggingface-hub>=0.19.4 in /opt/conda/lib/python3.12/site-packages (from datasets==2.17.0) (0.30.2)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.12/site-packages (from datasets==2.17.0) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.12/site-packages (from datasets==2.17.0) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.12/site-packages (from transformers==4.38.2) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in /opt/conda/lib/python3.12/site-packages (from transformers==4.38.2) (0.15.2)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.12/site-packages (from transformers==4.38.2) (0.5.3)\n",
      "Requirement already satisfied: responses<0.19 in /opt/conda/lib/python3.12/site-packages (from evaluate==0.4.0) (0.18.0)\n",
      "Requirement already satisfied: absl-py in /opt/conda/lib/python3.12/site-packages (from rouge_score==0.1.2) (2.2.0)\n",
      "Requirement already satisfied: nltk in /opt/conda/lib/python3.12/site-packages (from rouge_score==0.1.2) (3.9.1)\n",
      "Requirement already satisfied: six>=1.14.0 in /opt/conda/lib/python3.12/site-packages (from rouge_score==0.1.2) (1.17.0)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.12/site-packages (from peft==0.3.0) (5.9.8)\n",
      "Requirement already satisfied: torch>=1.13.0 in /opt/conda/lib/python3.12/site-packages (from peft==0.3.0) (2.5.1)\n",
      "Requirement already satisfied: accelerate in /opt/conda/lib/python3.12/site-packages (from peft==0.3.0) (1.5.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.12/site-packages (from huggingface-hub>=0.19.4->datasets==2.17.0) (4.13.2)\n",
      "Requirement already satisfied: urllib3>=1.25.10 in /opt/conda/lib/python3.12/site-packages (from responses<0.19->evaluate==0.4.0) (2.4.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/conda/lib/python3.12/site-packages (from requests>=2.19.0->datasets==2.17.0) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.12/site-packages (from requests>=2.19.0->datasets==2.17.0) (3.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.12/site-packages (from requests>=2.19.0->datasets==2.17.0) (2025.1.31)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.12/site-packages (from aiohttp->datasets==2.17.0) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.12/site-packages (from aiohttp->datasets==2.17.0) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.12/site-packages (from aiohttp->datasets==2.17.0) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.12/site-packages (from aiohttp->datasets==2.17.0) (6.4.3)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.12/site-packages (from aiohttp->datasets==2.17.0) (1.20.0)\n",
      "Requirement already satisfied: propcache>=0.2.1 in /opt/conda/lib/python3.12/site-packages (from yarl<2.0,>=1.0->aiohttp->datasets==2.17.0) (0.3.1)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.12/site-packages (from torch>=1.13.0->peft==0.3.0) (80.1.0)\n",
      "Requirement already satisfied: sympy!=1.13.2,>=1.13.1 in /opt/conda/lib/python3.12/site-packages (from torch>=1.13.0->peft==0.3.0) (1.14.0)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.12/site-packages (from torch>=1.13.0->peft==0.3.0) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.12/site-packages (from torch>=1.13.0->peft==0.3.0) (3.1.6)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.12/site-packages (from sympy!=1.13.2,>=1.13.1->torch>=1.13.0->peft==0.3.0) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.12/site-packages (from jinja2->torch>=1.13.0->peft==0.3.0) (3.0.2)\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.12/site-packages (from nltk->rouge_score==0.1.2) (8.1.8)\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.12/site-packages (from nltk->rouge_score==0.1.2) (1.5.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.12/site-packages (from pandas->datasets==2.17.0) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.12/site-packages (from pandas->datasets==2.17.0) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.12/site-packages (from pandas->datasets==2.17.0) (2025.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# First upgrade pip\n",
    "%pip install --upgrade pip\n",
    "\n",
    "# Install tensorflow and keras first\n",
    "%pip install tensorflow==2.18.0 keras==3.9.0\n",
    "\n",
    "# Install torch and torchdata\n",
    "%pip install --no-deps torch==2.5.1 torchdata==0.6.0 --quiet\n",
    "\n",
    "%pip install trl==0.5.0\n",
    "\n",
    "# Then install other packages except TRL\n",
    "%pip install -U \\\n",
    "    datasets==2.17.0 \\\n",
    "    transformers==4.38.2 \\\n",
    "    evaluate==0.4.0 \\\n",
    "    rouge_score==0.1.2 \\\n",
    "    peft==0.3.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer, GenerationConfig, TrainingArguments, Trainer, pipeline, AutoModelForSequenceClassification\n",
    "import torch\n",
    "import time\n",
    "import evaluate\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from peft import PeftModel, PeftConfig, LoraConfig, TaskType\n",
    "\n",
    "# trl: Transformer Reinforcement Learning library\n",
    "from trl import PPOTrainer, PPOConfig, AutoModelForSeq2SeqLMWithValueHead\n",
    "from trl import create_reference_model\n",
    "from trl.core import LengthSampler\n",
    "\n",
    "# tqdm library makes the loops show a smart progress meter.\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step will be to preprocess the dataset. You will take only a part of it, then filter the dialogues of a particular length (just to make those examples long enough and, at the same time, easy to read). Then wrap each dialogue with the instruction and tokenize the prompts. Save the token ids in the field `input_ids` and decoded version of the prompts in the field `query`.\n",
    "\n",
    "You could do that all step by step in the cell below, but it is a good habit to organize that all in a function `build_dataset`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "257335dd5a454449a2e9db9231eb13a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading readme:   0%|          | 0.00/4.65k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb4a7c368934461da54cf1c66c3dc45c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/11.3M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cfaff0483e554d17a827def71172b3d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/442k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26ad88e71e17477b812c7caaf65f84a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/1.35M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a775a8fb04641f5afc6c3e6c50433e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.12/site-packages/datasets/download/streaming_download_manager.py:784: FutureWarning: The 'verbose' keyword in pd.read_csv is deprecated and will be removed in a future version.\n",
      "  return pd.read_csv(xopen(filepath_or_buffer, \"rb\", download_config=download_config), **kwargs)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5794fc9df8bb4bb985b8f00ed981197d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.12/site-packages/datasets/download/streaming_download_manager.py:784: FutureWarning: The 'verbose' keyword in pd.read_csv is deprecated and will be removed in a future version.\n",
      "  return pd.read_csv(xopen(filepath_or_buffer, \"rb\", download_config=download_config), **kwargs)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dcaaf84351214a5da9ddc58db786d8f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.12/site-packages/datasets/download/streaming_download_manager.py:784: FutureWarning: The 'verbose' keyword in pd.read_csv is deprecated and will be removed in a future version.\n",
      "  return pd.read_csv(xopen(filepath_or_buffer, \"rb\", download_config=download_config), **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'dialogue', 'summary', 'topic'],\n",
       "        num_rows: 12460\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['id', 'dialogue', 'summary', 'topic'],\n",
       "        num_rows: 500\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['id', 'dialogue', 'summary', 'topic'],\n",
       "        num_rows: 1500\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "huggingface_dataset_name = \"knkarthick/dialogsum\"\n",
    "\n",
    "dataset = load_dataset(huggingface_dataset_name)\n",
    "\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.12/site-packages/huggingface_hub/file_download.py:896: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9904427868e4828b887a0ee2610b41f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.40k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bde308af3edf42ffb8e7d568efdfe73f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/990M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2aaf24c418ae48a9b413f90953479876",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c240f77f98b44abbe49dfaa5ae51f8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/2.54k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a86592f58034ac49a107d93e5122876",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "660255e1839f46029316ab41ece38b40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/2.42M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a20cc071eb14ca5a006e8d1e8f3cbd9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/2.20k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_name='google/flan-t5-base'\n",
    "\n",
    "original_model = AutoModelForSeq2SeqLM.from_pretrained(model_name, torch_dtype=torch.bfloat16)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='1.3'></a>\n",
    "### Test the Model with Zero Shot Inferencing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------------------------------\n",
      "INPUT PROMPT:\n",
      "\n",
      "Summarize the following conversation.\n",
      "\n",
      "#Person1#: Have you considered upgrading your system?\n",
      "#Person2#: Yes, but I'm not sure what exactly I would need.\n",
      "#Person1#: You could consider adding a painting program to your software. It would allow you to make up your own flyers and banners for advertising.\n",
      "#Person2#: That would be a definite bonus.\n",
      "#Person1#: You might also want to upgrade your hardware because it is pretty outdated now.\n",
      "#Person2#: How can we do that?\n",
      "#Person1#: You'd probably need a faster processor, to begin with. And you also need a more powerful hard disc, more memory and a faster modem. Do you have a CD-ROM drive?\n",
      "#Person2#: No.\n",
      "#Person1#: Then you might want to add a CD-ROM drive too, because most new software programs are coming out on Cds.\n",
      "#Person2#: That sounds great. Thanks.\n",
      "\n",
      "Summary:\n",
      "\n",
      "---------------------------------------------------------------------------------------------------\n",
      "BASELINE HUMAN SUMMARY:\n",
      "#Person1# teaches #Person2# how to upgrade software and hardware in #Person2#'s system.\n",
      "\n",
      "---------------------------------------------------------------------------------------------------\n",
      "MODEL GENERATION - ZERO SHOT:\n",
      "#Person1#: I'm thinking of upgrading my computer.\n"
     ]
    }
   ],
   "source": [
    "index = 200\n",
    "\n",
    "dialogue = dataset['test'][index]['dialogue']\n",
    "summary = dataset['test'][index]['summary']\n",
    "\n",
    "prompt = f\"\"\"\n",
    "Summarize the following conversation.\n",
    "\n",
    "{dialogue}\n",
    "\n",
    "Summary:\n",
    "\"\"\"\n",
    "\n",
    "inputs = tokenizer(prompt, return_tensors='pt')\n",
    "output = tokenizer.decode(\n",
    "    original_model.generate(\n",
    "        inputs[\"input_ids\"], \n",
    "        max_new_tokens=200,\n",
    "    )[0], \n",
    "    skip_special_tokens=True\n",
    ")\n",
    "\n",
    "dash_line = '-'.join('' for x in range(100))\n",
    "print(dash_line)\n",
    "print(f'INPUT PROMPT:\\n{prompt}')\n",
    "print(dash_line)\n",
    "print(f'BASELINE HUMAN SUMMARY:\\n{summary}\\n')\n",
    "print(dash_line)\n",
    "print(f'MODEL GENERATION - ZERO SHOT:\\n{output}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='2'></a>\n",
    "## Perform Parameter Efficient Fine-Tuning (LoRa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e96bbfd853164f559adf5218bf130eeb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/12460 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ebdfb7661caf4992b0c4c494622783a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/500 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81cfcb18f6b343219c01e74089ea8e5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1500 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes of the datasets:\n",
      "Training: (12460, 2)\n",
      "Validation: (500, 2)\n",
      "Test: (1500, 2)\n",
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['input_ids', 'labels'],\n",
      "        num_rows: 12460\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['input_ids', 'labels'],\n",
      "        num_rows: 500\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['input_ids', 'labels'],\n",
      "        num_rows: 1500\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "def tokenize_function(example):\n",
    "    start_prompt = 'Summarize the following conversation.\\n\\n'\n",
    "    end_prompt = '\\n\\nSummary: '\n",
    "    prompt = [start_prompt + dialogue + end_prompt for dialogue in example[\"dialogue\"]]\n",
    "    example['input_ids'] = tokenizer(prompt, padding=\"max_length\", truncation=True, return_tensors=\"pt\").input_ids\n",
    "    example['labels'] = tokenizer(example[\"summary\"], padding=\"max_length\", truncation=True, return_tensors=\"pt\").input_ids\n",
    "    \n",
    "    return example\n",
    "\n",
    "# The dataset actually contains 3 diff splits: train, validation, test.\n",
    "# The tokenize_function code is handling all data across all splits in batches.\n",
    "tokenized_datasets = dataset.map(tokenize_function, batched=True)\n",
    "tokenized_datasets = tokenized_datasets.remove_columns(['id', 'topic', 'dialogue', 'summary',])\n",
    "\n",
    "print(f\"Shapes of the datasets:\")\n",
    "print(f\"Training: {tokenized_datasets['train'].shape}\")\n",
    "print(f\"Validation: {tokenized_datasets['validation'].shape}\")\n",
    "print(f\"Test: {tokenized_datasets['test'].shape}\")\n",
    "\n",
    "print(tokenized_datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import LoraConfig, get_peft_model, TaskType\n",
    "\n",
    "lora_config = LoraConfig(\n",
    "    r=32, # Rank\n",
    "    lora_alpha=32,\n",
    "    target_modules=[\"q\", \"v\"],\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    task_type=TaskType.SEQ_2_SEQ_LM # FLAN-T5\n",
    ")\n",
    "\n",
    "peft_model = get_peft_model(original_model, \n",
    "                            lora_config) #add lora matrix to the base model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Accelerator.__init__() got an unexpected keyword argument 'dispatch_batches'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 12\u001b[0m\n\u001b[1;32m      1\u001b[0m output_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./peft-dialogue-summary-training-\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mint\u001b[39m(time\u001b[38;5;241m.\u001b[39mtime()))\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      3\u001b[0m peft_training_args \u001b[38;5;241m=\u001b[39m TrainingArguments(\n\u001b[1;32m      4\u001b[0m     output_dir\u001b[38;5;241m=\u001b[39moutput_dir,\n\u001b[1;32m      5\u001b[0m     auto_find_batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      9\u001b[0m     max_steps\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m    \n\u001b[1;32m     10\u001b[0m )\n\u001b[0;32m---> 12\u001b[0m peft_trainer \u001b[38;5;241m=\u001b[39m \u001b[43mTrainer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpeft_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpeft_training_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtokenized_datasets\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtrain\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/transformers/trainer.py:367\u001b[0m, in \u001b[0;36mTrainer.__init__\u001b[0;34m(self, model, args, data_collator, train_dataset, eval_dataset, tokenizer, model_init, compute_metrics, callbacks, optimizers, preprocess_logits_for_metrics)\u001b[0m\n\u001b[1;32m    364\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdeepspeed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    365\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_in_train \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m--> 367\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_accelerator_and_postprocess\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    369\u001b[0m \u001b[38;5;66;03m# memory metrics - must set up as early as possible\u001b[39;00m\n\u001b[1;32m    370\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_memory_tracker \u001b[38;5;241m=\u001b[39m TrainerMemoryTracker(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mskip_memory_metrics)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/transformers/trainer.py:4127\u001b[0m, in \u001b[0;36mTrainer.create_accelerator_and_postprocess\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   4122\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(accelerator_kwargs, \u001b[38;5;28mdict\u001b[39m):\n\u001b[1;32m   4123\u001b[0m         \u001b[38;5;66;03m# Some values may need to go through non-accelerate aligned defaults\u001b[39;00m\n\u001b[1;32m   4124\u001b[0m         \u001b[38;5;66;03m# and we need to run the `__post_init__` to set them\u001b[39;00m\n\u001b[1;32m   4125\u001b[0m         accelerator_kwargs \u001b[38;5;241m=\u001b[39m AcceleratorConfig(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39maccelerator_kwargs)\u001b[38;5;241m.\u001b[39mto_dict()\n\u001b[0;32m-> 4127\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator \u001b[38;5;241m=\u001b[39m \u001b[43mAccelerator\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   4128\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdeepspeed_plugin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdeepspeed_plugin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4129\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgradient_accumulation_plugin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgradient_accumulation_plugin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4130\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43maccelerator_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4131\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4132\u001b[0m \u001b[38;5;66;03m# some Trainer classes need to use `gather` instead of `gather_for_metrics`, thus we store a flag\u001b[39;00m\n\u001b[1;32m   4133\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgather_function \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39mgather_for_metrics\n",
      "\u001b[0;31mTypeError\u001b[0m: Accelerator.__init__() got an unexpected keyword argument 'dispatch_batches'"
     ]
    }
   ],
   "source": [
    "output_dir = f'./peft-dialogue-summary-training-{str(int(time.time()))}'\n",
    "\n",
    "peft_training_args = TrainingArguments(\n",
    "    output_dir=output_dir,\n",
    "    auto_find_batch_size=True,\n",
    "    learning_rate=1e-3, # Higher learning rate than full fine-tuning.\n",
    "    num_train_epochs=1,\n",
    "    logging_steps=1,\n",
    "    max_steps=1    \n",
    ")\n",
    "    \n",
    "peft_trainer = Trainer(\n",
    "    model=peft_model,\n",
    "    args=peft_training_args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "peft_trainer.train()\n",
    "\n",
    "peft_model_path=\"./peft-dialogue-summary-checkpoint-local\"\n",
    "\n",
    "peft_trainer.model.save_pretrained(peft_model_path)\n",
    "tokenizer.save_pretrained(peft_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "peft_model.requires_grad_(False) #turn off gradients for evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download: s3://dlai-generative-ai/models/peft-dialogue-summary-checkpoint/tokenizer_config.json to peft-dialogue-summary-checkpoint-from-s3/tokenizer_config.json\n",
      "download: s3://dlai-generative-ai/models/peft-dialogue-summary-checkpoint/adapter_config.json to peft-dialogue-summary-checkpoint-from-s3/adapter_config.json\n",
      "download: s3://dlai-generative-ai/models/peft-dialogue-summary-checkpoint/special_tokens_map.json to peft-dialogue-summary-checkpoint-from-s3/special_tokens_map.json\n",
      "download: s3://dlai-generative-ai/models/peft-dialogue-summary-checkpoint/adapter_model.bin to peft-dialogue-summary-checkpoint-from-s3/adapter_model.bin\n",
      "download: s3://dlai-generative-ai/models/peft-dialogue-summary-checkpoint/tokenizer.json to peft-dialogue-summary-checkpoint-from-s3/tokenizer.json\n"
     ]
    }
   ],
   "source": [
    "!aws s3 cp --recursive s3://dlai-generative-ai/models/peft-dialogue-summary-checkpoint/ ./peft-dialogue-summary-checkpoint-from-s3/ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-r--r-- 1 sagemaker-user users 14M May 15  2023 ./peft-dialogue-summary-checkpoint-from-s3/adapter_model.bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "!ls -alh ./peft-dialogue-summary-checkpoint-from-s3/adapter_model.bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_number_of_trainable_model_parameters(model):\n",
    "    trainable_model_params = 0\n",
    "    all_model_params = 0\n",
    "    for _, param in model.named_parameters():\n",
    "        all_model_params += param.numel()\n",
    "        if param.requires_grad:\n",
    "            trainable_model_params += param.numel()\n",
    "    return f\"\\ntrainable model parameters: {trainable_model_params}\\nall model parameters: {all_model_params}\\npercentage of trainable model parameters: {100 * trainable_model_params / all_model_params:.2f}%\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.12/site-packages/huggingface_hub/file_download.py:896: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PEFT model parameters to be updated:\n",
      "\n",
      "trainable model parameters: 3538944\n",
      "all model parameters: 251116800\n",
      "percentage of trainable model parameters: 1.41%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.12/site-packages/peft/peft_model.py:372: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  adapters_weights = torch.load(\n"
     ]
    }
   ],
   "source": [
    "lora_config = LoraConfig(\n",
    "    r=32, # Rank\n",
    "    lora_alpha=32,\n",
    "    target_modules=[\"q\", \"v\"],\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    task_type=TaskType.SEQ_2_SEQ_LM # FLAN-T5\n",
    ")\n",
    "\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name, \n",
    "                                              torch_dtype=torch.bfloat16)\n",
    "\n",
    "peft_model = PeftModel.from_pretrained(model, \n",
    "                                       './peft-dialogue-summary-checkpoint-from-s3/', \n",
    "                                       lora_config=lora_config,\n",
    "                                       torch_dtype=torch.bfloat16, \n",
    "                                       device_map=\"auto\",                                       \n",
    "                                       is_trainable=True)\n",
    "\n",
    "print(f'PEFT model parameters to be updated:\\n{print_number_of_trainable_model_parameters(peft_model)}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the Model Qualitatively (Human Evaluation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------------------------------\n",
      "BASELINE HUMAN SUMMARY:\n",
      "#Person1# teaches #Person2# how to upgrade software and hardware in #Person2#'s system.\n",
      "---------------------------------------------------------------------------------------------------\n",
      "ORIGINAL MODEL:\n",
      "#Person1#: I'm thinking of upgrading my computer.\n",
      "---------------------------------------------------------------------------------------------------\n",
      "PEFT MODEL: #Person1# recommends adding a painting program to #Person2#'s software and upgrading hardware. #Person2# also wants to upgrade the hardware because it's outdated now.\n"
     ]
    }
   ],
   "source": [
    "index = 200\n",
    "dialogue = dataset['test'][index]['dialogue']\n",
    "human_baseline_summary = dataset['test'][index]['summary']\n",
    "\n",
    "prompt = f\"\"\"\n",
    "Summarize the following conversation.\n",
    "\n",
    "{dialogue}\n",
    "\n",
    "Summary: \"\"\"\n",
    "\n",
    "input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids\n",
    "\n",
    "original_model_outputs = original_model.generate(input_ids=input_ids, generation_config=GenerationConfig(max_new_tokens=200, num_beams=1))\n",
    "original_model_text_output = tokenizer.decode(original_model_outputs[0], skip_special_tokens=True)\n",
    "\n",
    "peft_model_outputs = peft_model.generate(input_ids=input_ids, generation_config=GenerationConfig(max_new_tokens=200, num_beams=1))\n",
    "peft_model_text_output = tokenizer.decode(peft_model_outputs[0], skip_special_tokens=True)\n",
    "\n",
    "print(dash_line)\n",
    "print(f'BASELINE HUMAN SUMMARY:\\n{human_baseline_summary}')\n",
    "print(dash_line)\n",
    "print(f'ORIGINAL MODEL:\\n{original_model_text_output}')\n",
    "print(dash_line)\n",
    "print(f'PEFT MODEL: {peft_model_text_output}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='3.4'></a>\n",
    "### Evaluate the Model Quantitatively (with ROUGE Metric)\n",
    "Perform inferences for the sample of the test dataset (only 10 dialogues and summaries to save time). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>human_baseline_summaries</th>\n",
       "      <th>original_model_summaries</th>\n",
       "      <th>peft_model_summaries</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ms. Dawson helps #Person1# to write a memo to ...</td>\n",
       "      <td>#Person1#: I need to take a dictation for you.</td>\n",
       "      <td>#Person1# asks Ms. Dawson to take a dictation ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>In order to prevent employees from wasting tim...</td>\n",
       "      <td>#Person1#: I need to take a dictation for you.</td>\n",
       "      <td>#Person1# asks Ms. Dawson to take a dictation ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ms. Dawson takes a dictation for #Person1# abo...</td>\n",
       "      <td>#Person1#: I need to take a dictation for you.</td>\n",
       "      <td>#Person1# asks Ms. Dawson to take a dictation ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>#Person2# arrives late because of traffic jam....</td>\n",
       "      <td>The traffic jam at the Carrefour intersection ...</td>\n",
       "      <td>#Person2# got stuck in traffic and #Person1# s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>#Person2# decides to follow #Person1#'s sugges...</td>\n",
       "      <td>The traffic jam at the Carrefour intersection ...</td>\n",
       "      <td>#Person2# got stuck in traffic and #Person1# s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>#Person2# complains to #Person1# about the tra...</td>\n",
       "      <td>The traffic jam at the Carrefour intersection ...</td>\n",
       "      <td>#Person2# got stuck in traffic and #Person1# s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>#Person1# tells Kate that Masha and Hero get d...</td>\n",
       "      <td>Masha and Hero are getting divorced.</td>\n",
       "      <td>Kate tells #Person2# Masha and Hero are gettin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>#Person1# tells Kate that Masha and Hero are g...</td>\n",
       "      <td>Masha and Hero are getting divorced.</td>\n",
       "      <td>Kate tells #Person2# Masha and Hero are gettin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>#Person1# and Kate talk about the divorce betw...</td>\n",
       "      <td>Masha and Hero are getting divorced.</td>\n",
       "      <td>Kate tells #Person2# Masha and Hero are gettin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>#Person1# and Brian are at the birthday party ...</td>\n",
       "      <td>#Person1#: Happy birthday, Brian. #Person2#: I...</td>\n",
       "      <td>Brian remembers his birthday and invites #Pers...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            human_baseline_summaries  \\\n",
       "0  Ms. Dawson helps #Person1# to write a memo to ...   \n",
       "1  In order to prevent employees from wasting tim...   \n",
       "2  Ms. Dawson takes a dictation for #Person1# abo...   \n",
       "3  #Person2# arrives late because of traffic jam....   \n",
       "4  #Person2# decides to follow #Person1#'s sugges...   \n",
       "5  #Person2# complains to #Person1# about the tra...   \n",
       "6  #Person1# tells Kate that Masha and Hero get d...   \n",
       "7  #Person1# tells Kate that Masha and Hero are g...   \n",
       "8  #Person1# and Kate talk about the divorce betw...   \n",
       "9  #Person1# and Brian are at the birthday party ...   \n",
       "\n",
       "                            original_model_summaries  \\\n",
       "0     #Person1#: I need to take a dictation for you.   \n",
       "1     #Person1#: I need to take a dictation for you.   \n",
       "2     #Person1#: I need to take a dictation for you.   \n",
       "3  The traffic jam at the Carrefour intersection ...   \n",
       "4  The traffic jam at the Carrefour intersection ...   \n",
       "5  The traffic jam at the Carrefour intersection ...   \n",
       "6               Masha and Hero are getting divorced.   \n",
       "7               Masha and Hero are getting divorced.   \n",
       "8               Masha and Hero are getting divorced.   \n",
       "9  #Person1#: Happy birthday, Brian. #Person2#: I...   \n",
       "\n",
       "                                peft_model_summaries  \n",
       "0  #Person1# asks Ms. Dawson to take a dictation ...  \n",
       "1  #Person1# asks Ms. Dawson to take a dictation ...  \n",
       "2  #Person1# asks Ms. Dawson to take a dictation ...  \n",
       "3  #Person2# got stuck in traffic and #Person1# s...  \n",
       "4  #Person2# got stuck in traffic and #Person1# s...  \n",
       "5  #Person2# got stuck in traffic and #Person1# s...  \n",
       "6  Kate tells #Person2# Masha and Hero are gettin...  \n",
       "7  Kate tells #Person2# Masha and Hero are gettin...  \n",
       "8  Kate tells #Person2# Masha and Hero are gettin...  \n",
       "9  Brian remembers his birthday and invites #Pers...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dialogues = dataset['test'][0:10]['dialogue']\n",
    "human_baseline_summaries = dataset['test'][0:10]['summary']\n",
    "\n",
    "original_model_summaries = []\n",
    "instruct_model_summaries = []\n",
    "peft_model_summaries = []\n",
    "\n",
    "for idx, dialogue in enumerate(dialogues):\n",
    "    prompt = f\"\"\"\n",
    "Summarize the following conversation.\n",
    "\n",
    "{dialogue}\n",
    "\n",
    "Summary: \"\"\"\n",
    "    \n",
    "    input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids\n",
    "\n",
    "    human_baseline_text_output = human_baseline_summaries[idx]\n",
    "    \n",
    "    original_model_outputs = original_model.generate(input_ids=input_ids, generation_config=GenerationConfig(max_new_tokens=200))\n",
    "    original_model_text_output = tokenizer.decode(original_model_outputs[0], skip_special_tokens=True)\n",
    "\n",
    "    peft_model_outputs = peft_model.generate(input_ids=input_ids, generation_config=GenerationConfig(max_new_tokens=200))\n",
    "    peft_model_text_output = tokenizer.decode(peft_model_outputs[0], skip_special_tokens=True)\n",
    "\n",
    "    original_model_summaries.append(original_model_text_output)\n",
    "    peft_model_summaries.append(peft_model_text_output)\n",
    "\n",
    "zipped_summaries = list(zip(human_baseline_summaries, original_model_summaries, peft_model_summaries))\n",
    " \n",
    "df = pd.DataFrame(zipped_summaries, columns = ['human_baseline_summaries', 'original_model_summaries', 'peft_model_summaries'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9eb27c3c68ea4ede9cb59dd960ba59f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/6.27k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ORIGINAL MODEL:\n",
      "{'rouge1': 0.24089921652421653, 'rouge2': 0.11769053708439897, 'rougeL': 0.22001958689458687, 'rougeLsum': 0.22134175465057818}\n",
      "PEFT MODEL:\n",
      "{'rouge1': 0.3725351062275605, 'rouge2': 0.12138811933618107, 'rougeL': 0.27620639623170606, 'rougeLsum': 0.2758134870822362}\n"
     ]
    }
   ],
   "source": [
    "rouge = evaluate.load('rouge')\n",
    "\n",
    "original_model_results = rouge.compute(\n",
    "    predictions=original_model_summaries,\n",
    "    references=human_baseline_summaries[0:len(original_model_summaries)],\n",
    "    use_aggregator=True,\n",
    "    use_stemmer=True,\n",
    ")\n",
    "\n",
    "peft_model_results = rouge.compute(\n",
    "    predictions=peft_model_summaries,\n",
    "    references=human_baseline_summaries[0:len(peft_model_summaries)],\n",
    "    use_aggregator=True,\n",
    "    use_stemmer=True,\n",
    ")\n",
    "\n",
    "print('ORIGINAL MODEL:')\n",
    "print(original_model_results)\n",
    "print('PEFT MODEL:')\n",
    "print(peft_model_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Absolute percentage improvement of PEFT MODEL over ORIGINAL MODEL\n",
      "rouge1: 13.16%\n",
      "rouge2: 0.37%\n",
      "rougeL: 5.62%\n",
      "rougeLsum: 5.45%\n"
     ]
    }
   ],
   "source": [
    "print(\"Absolute percentage improvement of PEFT MODEL over ORIGINAL MODEL\")\n",
    "\n",
    "improvement = (np.array(list(peft_model_results.values())) - np.array(list(original_model_results.values())))\n",
    "for key, value in zip(peft_model_results.keys(), improvement):\n",
    "    print(f'{key}: {value*100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RLHF for Toxicity Evaluator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step will be to preprocess the dataset. We will take only a part of it, then filter the dialogues of a particular length (just to make those examples long enough and, at the same time, easy to read). Then wrap each dialogue with the instruction and tokenize the prompts. Save the token ids in the field `input_ids` and decoded version of the prompts in the field `query`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9503b49ace94d9886bb88ef677d2b8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/12460 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb404fc5357a4f9b9bb12c20c2275570",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10022 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['id', 'dialogue', 'summary', 'topic', 'input_ids', 'query'],\n",
      "        num_rows: 8017\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['id', 'dialogue', 'summary', 'topic', 'input_ids', 'query'],\n",
      "        num_rows: 2005\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "def build_dataset(dataset_name,\n",
    "                  input_min_text_length, \n",
    "                  input_max_text_length):\n",
    "\n",
    "    \"\"\"\n",
    "    Preprocess the dataset and split it into train and test parts.\n",
    "\n",
    "    Parameters:\n",
    "    - model_name (str): Tokenizer model name.\n",
    "    - dataset_name (str): Name of the dataset to load.\n",
    "    - input_min_text_length (int): Minimum length of the dialogues.\n",
    "    - input_max_text_length (int): Maximum length of the dialogues.\n",
    "        \n",
    "    Returns:\n",
    "    - dataset_splits (datasets.dataset_dict.DatasetDict): Preprocessed dataset containing train and test parts.\n",
    "    \"\"\"\n",
    "    \n",
    "    # load dataset (only \"train\" part will be enough for this lab).\n",
    "    dataset = load_dataset(dataset_name, split=\"train\")\n",
    "    \n",
    "    # Filter the dialogues of length between input_min_text_length and input_max_text_length characters.\n",
    "    dataset = dataset.filter(lambda x: len(x[\"dialogue\"]) > input_min_text_length and len(x[\"dialogue\"]) <= input_max_text_length, batched=False)\n",
    "    \n",
    "    def tokenize(sample):\n",
    "        \n",
    "        # Wrap each dialogue with the instruction.\n",
    "        prompt = f\"\"\"\n",
    "Summarize the following conversation.\n",
    "\n",
    "{sample[\"dialogue\"]}\n",
    "\n",
    "Summary:\n",
    "\"\"\"\n",
    "        sample[\"input_ids\"] = tokenizer.encode(prompt)\n",
    "        \n",
    "        # This must be called \"query\", which is a requirement of our PPO library.\n",
    "        sample[\"query\"] = tokenizer.decode(sample[\"input_ids\"])\n",
    "        return sample\n",
    "\n",
    "    # Tokenize each dialogue.\n",
    "    dataset = dataset.map(tokenize, batched=False)\n",
    "    dataset.set_format(type=\"torch\")\n",
    "    \n",
    "    # Split the dataset into train and test parts.\n",
    "    dataset_splits = dataset.train_test_split(test_size=0.2, shuffle=False, seed=42)\n",
    "\n",
    "    return dataset_splits\n",
    "\n",
    "dataset = build_dataset(dataset_name=huggingface_dataset_name,\n",
    "                        input_min_text_length=200, \n",
    "                        input_max_text_length=1000)\n",
    "\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enable gradients only for LoRA weights\n",
    "for name, param in peft_model.named_parameters():\n",
    "    if \"lora\" in name:  # LoRA weights typically have \"lora\" in their names\n",
    "        param.requires_grad = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='3'></a>\n",
    "## 3 - Perform Fine-Tuning to Detoxify the Summaries\n",
    "Optimize a RL policy against the reward model using Proximal Policy Optimization (PPO)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We prepare the Proximal Policy Optimization (PPO) model passing the instruct-fine-tuned PEFT model to it. PPO will be used to optimize the RL policy against the reward model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ValueHead(\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      "  (summary): Linear(in_features=768, out_features=1, bias=True)\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "ppo_model = AutoModelForSeq2SeqLMWithValueHead.from_pretrained(peft_model,                                                               \n",
    "                                                               torch_dtype=torch.bfloat16,\n",
    "                                                               is_trainable=True)\n",
    "\n",
    "print(ppo_model.v_head)\n",
    "\n",
    "ref_model = create_reference_model(ppo_model) #reference model for PPO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='2.2'></a>\n",
    "### Prepare Reward Model\n",
    "\n",
    "We use [Meta AI's RoBERTa-based hate speech model](https://huggingface.co/facebook/roberta-hate-speech-dynabench-r4-target) for the reward model. This model will output **logits** and then predict probabilities across two classes: `nothate` and `hate`. The logits of the output `nothate` will be taken as a positive reward. Then, the model will be fine-tuned with PPO using those reward values.\n",
    "\n",
    "Notice that the model label `0` will correspond to the class `nothate` and label `1` to the class `hate`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.12/site-packages/huggingface_hub/file_download.py:896: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "956a1350ae1f44b0aca53223357495e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/1.11k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5db4021435e94673ab917935880bdf1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50c29cc3c38a45329ad7bb28e8cc990c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c45f0de0ea514adb9b59f7a8f7da1b13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76d88e99a5504b4e956194e9c6d34f72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/816 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "WARNING:huggingface_hub.file_download:Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "940342882d044dc0a062d3db41ad1316",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/499M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'nothate', 1: 'hate'}\n"
     ]
    }
   ],
   "source": [
    "toxicity_model_name = \"facebook/roberta-hate-speech-dynabench-r4-target\"\n",
    "toxicity_tokenizer = AutoTokenizer.from_pretrained(toxicity_model_name, device_map=\"auto\")\n",
    "toxicity_model = AutoModelForSequenceClassification.from_pretrained(toxicity_model_name, device_map=\"auto\")\n",
    "print(toxicity_model.config.id2label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logits [not hate, hate]: [3.1140999794006348, -2.489616632461548]\n",
      "probabilities [not hate, hate]: [0.9963293671607971, 0.003670621896162629]\n",
      "reward (high): [3.1140999794006348]\n",
      "logits [not hate, hate]: [-0.6921164989471436, 0.3722708523273468]\n",
      "probabilities [not hate, hate]: [0.2564719021320343, 0.7435280680656433]\n",
      "reward (low): [-0.6921164989471436]\n"
     ]
    }
   ],
   "source": [
    "#Manual test of the toxicity model\n",
    "non_toxic_text = \"#Person 1# tells Tommy that he didn't like the movie.\"\n",
    "\n",
    "toxicity_input_ids = toxicity_tokenizer(non_toxic_text, return_tensors=\"pt\").input_ids\n",
    "\n",
    "logits = toxicity_model(input_ids=toxicity_input_ids).logits\n",
    "print(f'logits [not hate, hate]: {logits.tolist()[0]}')\n",
    "\n",
    "# Print the probabilities for [not hate, hate]\n",
    "probabilities = logits.softmax(dim=-1).tolist()[0]\n",
    "print(f'probabilities [not hate, hate]: {probabilities}')\n",
    "\n",
    "# get the logits for \"not hate\" - this is the reward!\n",
    "not_hate_index = 0\n",
    "nothate_reward = (logits[:, not_hate_index]).tolist()\n",
    "print(f'reward (high): {nothate_reward}')\n",
    "\n",
    "#Do same for toxic text\n",
    "toxic_text = \"#Person 1# tells Tommy that the movie was terrible, dumb and stupid.\"\n",
    "\n",
    "toxicity_input_ids = toxicity_tokenizer(toxic_text, return_tensors=\"pt\").input_ids\n",
    "\n",
    "logits = toxicity_model(toxicity_input_ids).logits\n",
    "print(f'logits [not hate, hate]: {logits.tolist()[0]}')\n",
    "\n",
    "# Print the probabilities for [not hate, hate]\n",
    "probabilities = logits.softmax(dim=-1).tolist()[0]\n",
    "print(f'probabilities [not hate, hate]: {probabilities}')\n",
    "\n",
    "# Get the logits for \"not hate\" - this is the reward!\n",
    "nothate_reward = (logits[:, not_hate_index]).tolist() \n",
    "print(f'reward (low): {nothate_reward}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup Hugging Face inference pipeline to simplify the code for the toxicity reward model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reward model output:\n",
      "For non-toxic text\n",
      "[{'label': 'nothate', 'score': 3.1140999794006348}, {'label': 'hate', 'score': -2.489616632461548}]\n",
      "[{'label': 'nothate', 'score': 0.9963293671607971}, {'label': 'hate', 'score': 0.0036706216633319855}]\n",
      "For toxic text\n",
      "[{'label': 'hate', 'score': 0.3722708523273468}, {'label': 'nothate', 'score': -0.6921164989471436}]\n",
      "[{'label': 'hate', 'score': 0.7435280680656433}, {'label': 'nothate', 'score': 0.2564719319343567}]\n"
     ]
    }
   ],
   "source": [
    "device = 0 if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "sentiment_pipe = pipeline(\"sentiment-analysis\", \n",
    "                          model=toxicity_model_name, \n",
    "                          device=device,\n",
    "                          framework=\"pt\")\n",
    "\n",
    "reward_logits_kwargs = {\n",
    "    \"top_k\": None, # Return all scores.\n",
    "    \"function_to_apply\": \"none\", # Set to \"none\" to retrieve raw logits.\n",
    "    \"batch_size\": 16\n",
    "}\n",
    "\n",
    "reward_probabilities_kwargs = {\n",
    "    \"top_k\": None, # Return all scores.\n",
    "    \"function_to_apply\": \"softmax\", # Set to \"softmax\" to apply softmax and retrieve probabilities.\n",
    "    \"batch_size\": 16\n",
    "}\n",
    "\n",
    "print(\"Reward model output:\")\n",
    "print(\"For non-toxic text\")\n",
    "print(sentiment_pipe(non_toxic_text, **reward_logits_kwargs))\n",
    "print(sentiment_pipe(non_toxic_text, **reward_probabilities_kwargs))\n",
    "print(\"For toxic text\")\n",
    "print(sentiment_pipe(toxic_text, **reward_logits_kwargs))\n",
    "print(sentiment_pipe(toxic_text, **reward_probabilities_kwargs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='2.3'></a>\n",
    "### Evaluate Toxicity\n",
    "\n",
    "To evaluate the model before and after fine-tuning/detoxification you need to set up the [toxicity evaluation metric](https://huggingface.co/spaces/evaluate-measurement/toxicity). The **toxicity score** is a decimal value between 0 and 1 where 1 is the highest toxicity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8881260e95654efe99fd5623e94eab99",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/6.08k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "toxicity_evaluator = evaluate.load(\"toxicity\", \n",
    "                                    toxicity_model_name,\n",
    "                                    module_type=\"measurement\",\n",
    "                                    toxic_label=\"hate\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Toxicity score for non-toxic text:\n",
      "[0.0036706216633319855]\n",
      "\n",
      "Toxicity score for toxic text:\n",
      "[0.7435280680656433]\n"
     ]
    }
   ],
   "source": [
    "toxicity_score = toxicity_evaluator.compute(predictions=[\n",
    "    non_toxic_text\n",
    "])\n",
    "\n",
    "print(\"Toxicity score for non-toxic text:\")\n",
    "print(toxicity_score[\"toxicity\"])\n",
    "\n",
    "toxicity_score = toxicity_evaluator.compute(predictions=[\n",
    "    toxic_text\n",
    "])\n",
    "\n",
    "print(\"\\nToxicity score for toxic text:\")\n",
    "print(toxicity_score[\"toxicity\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This evaluator can be used to compute the toxicity of the dialogues prepared earlier. You will need to pass the test dataset (`dataset[\"test\"]`), the same tokenizer, the frozen PEFT model, and the toxicity evaluator. It is convenient to wrap the required steps in the function `evaluate_toxicity`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_toxicity(model, \n",
    "                      toxicity_evaluator, \n",
    "                      tokenizer, \n",
    "                      dataset, \n",
    "                      num_samples):\n",
    "    \n",
    "    \"\"\"\n",
    "    Preprocess the dataset and split it into train and test parts.\n",
    "\n",
    "    Parameters:\n",
    "    - model (trl model): Model to be evaluated.\n",
    "    - toxicity_evaluator (evaluate_modules toxicity metrics): Toxicity evaluator.\n",
    "    - tokenizer (transformers tokenizer): Tokenizer to be used.\n",
    "    - dataset (dataset): Input dataset for the evaluation.\n",
    "    - num_samples (int): Maximum number of samples for the evaluation.\n",
    "        \n",
    "    Returns:\n",
    "    tuple: A tuple containing two numpy.float64 values:\n",
    "    - mean (numpy.float64): Mean of the samples toxicity.\n",
    "    - std (numpy.float64): Standard deviation of the samples toxicity.\n",
    "    \"\"\"\n",
    "\n",
    "    max_new_tokens=100\n",
    "\n",
    "    toxicities = []\n",
    "    input_texts = []\n",
    "    for i, sample in tqdm(enumerate(dataset)):\n",
    "        input_text = sample[\"query\"]\n",
    "\n",
    "        if i > num_samples:\n",
    "            break\n",
    "            \n",
    "        input_ids = tokenizer(input_text, return_tensors=\"pt\", padding=True).input_ids\n",
    "        \n",
    "        generation_config = GenerationConfig(max_new_tokens=max_new_tokens,\n",
    "                                             top_k=0.0,\n",
    "                                             top_p=1.0,\n",
    "                                             do_sample=True)\n",
    "\n",
    "        response_token_ids = model.generate(input_ids=input_ids,\n",
    "                                            generation_config=generation_config)\n",
    "        \n",
    "        generated_text = tokenizer.decode(response_token_ids[0], skip_special_tokens=True)\n",
    "        \n",
    "        toxicity_score = toxicity_evaluator.compute(predictions=[(input_text + \" \" + generated_text)])\n",
    "\n",
    "        toxicities.extend(toxicity_score[\"toxicity\"])\n",
    "\n",
    "    # Compute mean & std using np.\n",
    "    mean = np.mean(toxicities)\n",
    "    std = np.std(toxicities)\n",
    "        \n",
    "    return mean, std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now perform the calculation of the model toxicity before fine-tuning/detoxification:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11it [00:25,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "toxicity [mean, std] before detox: [0.04205592766150155, 0.05528711040288591]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_name, device_map=\"auto\")\n",
    "\n",
    "mean_before_detoxification, std_before_detoxification = evaluate_toxicity(model=ref_model, \n",
    "                                                                          toxicity_evaluator=toxicity_evaluator, \n",
    "                                                                          tokenizer=tokenizer, \n",
    "                                                                          dataset=dataset[\"test\"], \n",
    "                                                                          num_samples=10)\n",
    "\n",
    "print(f'toxicity [mean, std] before detox: [{mean_before_detoxification}, {std_before_detoxification}]')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='3'></a>\n",
    "## Perform Fine-Tuning to Detoxify the Summaries\n",
    "Optimize a RL policy against the reward model using Proximal Policy Optimization (PPO)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collator input: [{'key1': 'value1', 'key2': 'value2', 'key3': 'value3'}]\n",
      "Collator output: {'key1': ['value1'], 'key2': ['value2'], 'key3': ['value3']}\n"
     ]
    }
   ],
   "source": [
    "def collator(data):\n",
    "    return dict((key, [d[key] for d in data]) for key in data[0])\n",
    "\n",
    "test_data = [{\"key1\": \"value1\", \"key2\": \"value2\", \"key3\": \"value3\"}]\n",
    "print(f'Collator input: {test_data}')\n",
    "print(f'Collator output: {collator(test_data)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up the configuration parameters. Load the `ppo_model`,the tokenizer, and the model `ref_model`. The first model is optimized while the second model serves as a reference to calculate the KL-divergence from the starting point. This works as an additional reward signal in the PPO training to make sure the optimized model does not deviate too much from the original LLM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate=1.41e-5\n",
    "max_ppo_epochs=1\n",
    "mini_batch_size=4\n",
    "batch_size=16\n",
    "\n",
    "config = PPOConfig(\n",
    "    model_name=model_name,    \n",
    "    learning_rate=learning_rate,\n",
    "    ppo_epochs=max_ppo_epochs,\n",
    "    mini_batch_size=mini_batch_size,\n",
    "    batch_size=batch_size\n",
    ")\n",
    "\n",
    "ppo_trainer = PPOTrainer(config=config, \n",
    "                         model=ppo_model, \n",
    "                         ref_model=ref_model, \n",
    "                         tokenizer=tokenizer, \n",
    "                         dataset=dataset[\"train\"], \n",
    "                         data_collator=collator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [01:45, 105.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objective/kl: 31.744482040405273\n",
      "ppo/returns/mean: -0.5815266370773315\n",
      "ppo/policy/advantages_mean: 0.014206957072019577\n",
      "---------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [03:22, 100.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objective/kl: 32.487403869628906\n",
      "ppo/returns/mean: -0.7418457269668579\n",
      "ppo/policy/advantages_mean: 0.00712035596370697\n",
      "---------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3it [04:49, 94.11s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objective/kl: 27.899694442749023\n",
      "ppo/returns/mean: -0.631524920463562\n",
      "ppo/policy/advantages_mean: 0.028682002797722816\n",
      "---------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4it [06:12, 89.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objective/kl: 23.7159481048584\n",
      "ppo/returns/mean: -0.322004497051239\n",
      "ppo/policy/advantages_mean: 0.01962106302380562\n",
      "---------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5it [07:36, 87.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objective/kl: 22.943431854248047\n",
      "ppo/returns/mean: -0.2040756344795227\n",
      "ppo/policy/advantages_mean: 0.0010558790527284145\n",
      "---------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6it [09:20, 93.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objective/kl: 29.178905487060547\n",
      "ppo/returns/mean: -0.49285051226615906\n",
      "ppo/policy/advantages_mean: 0.03843369707465172\n",
      "---------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [10:53, 93.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objective/kl: 30.15130615234375\n",
      "ppo/returns/mean: -0.6007474064826965\n",
      "ppo/policy/advantages_mean: 0.009798852726817131\n",
      "---------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8it [12:19, 90.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objective/kl: 23.264793395996094\n",
      "ppo/returns/mean: -0.35638925433158875\n",
      "ppo/policy/advantages_mean: -0.0009175315499305725\n",
      "---------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9it [13:53, 92.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objective/kl: 22.926286697387695\n",
      "ppo/returns/mean: -0.37974193692207336\n",
      "ppo/policy/advantages_mean: 0.005319703370332718\n",
      "---------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [15:25, 92.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objective/kl: 28.447803497314453\n",
      "ppo/returns/mean: -0.49372848868370056\n",
      "ppo/policy/advantages_mean: 0.0025759749114513397\n",
      "---------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "output_min_length = 100\n",
    "output_max_length = 400\n",
    "output_length_sampler = LengthSampler(output_min_length, output_max_length)\n",
    "\n",
    "generation_kwargs = {\n",
    "    \"min_length\": 5,\n",
    "    \"top_k\": 0.0,\n",
    "    \"top_p\": 1.0,\n",
    "    \"do_sample\": True\n",
    "}\n",
    "\n",
    "reward_kwargs = {\n",
    "    \"top_k\": None, # Return all scores.\n",
    "    \"function_to_apply\": \"none\", # we want the raw logits without softmax.\n",
    "    \"batch_size\": 16\n",
    "}\n",
    "\n",
    "max_ppo_steps = 10\n",
    "\n",
    "for step, batch in tqdm(enumerate(ppo_trainer.dataloader)):\n",
    "    # Break when you reach max_steps.\n",
    "    if step >= max_ppo_steps:\n",
    "        break   \n",
    "\n",
    "    prompt_tensors = batch[\"input_ids\"]\n",
    "\n",
    "    # Get response from FLAN-T5/PEFT LLM.\n",
    "    summary_tensors = []\n",
    "\n",
    "    for prompt_tensor in prompt_tensors:\n",
    "        max_new_tokens = output_length_sampler()        \n",
    "            \n",
    "        generation_kwargs[\"max_new_tokens\"] = max_new_tokens\n",
    "        summary = ppo_trainer.generate(prompt_tensor, **generation_kwargs)\n",
    "        \n",
    "        summary_tensors.append(summary.squeeze()[-max_new_tokens:])\n",
    "        \n",
    "    # This needs to be called \"response\".\n",
    "    batch[\"response\"] = [tokenizer.decode(r.squeeze()) for r in summary_tensors]\n",
    "\n",
    "    # Compute reward outputs.\n",
    "    query_response_pairs = [q + r for q, r in zip(batch[\"query\"], batch[\"response\"])]    \n",
    "    rewards = sentiment_pipe(query_response_pairs, **reward_kwargs)\n",
    "\n",
    "    # we use the `nothate` item because this is the score for the positive `nothate` class.\n",
    "    reward_tensors = [torch.tensor(reward[not_hate_index][\"score\"]) for reward in rewards]    \n",
    "\n",
    "    # Run PPO step.\n",
    "    stats = ppo_trainer.step(prompt_tensors, summary_tensors, reward_tensors)\n",
    "    ppo_trainer.log_stats(stats, batch, reward_tensors)\n",
    "    \n",
    "    print(f'objective/kl: {stats[\"objective/kl\"]}')\n",
    "    print(f'ppo/returns/mean: {stats[\"ppo/returns/mean\"]}')\n",
    "    print(f'ppo/policy/advantages_mean: {stats[\"ppo/policy/advantages_mean\"]}')\n",
    "    print('-'.join('' for x in range(100)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11it [00:23,  2.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "toxicity [mean, std] after detox: [0.04247189113150605, 0.05072798581343112]\n",
      "Percentage improvement of toxicity score after detoxification:\n",
      "mean: -0.99%\n",
      "std: 8.25%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "mean_after_detoxification, std_after_detoxification = evaluate_toxicity(model=ppo_model, \n",
    "                                                                        toxicity_evaluator=toxicity_evaluator, \n",
    "                                                                        tokenizer=tokenizer, \n",
    "                                                                        dataset=dataset[\"test\"], \n",
    "                                                                        num_samples=10)\n",
    "print(f'toxicity [mean, std] after detox: [{mean_after_detoxification}, {std_after_detoxification}]')\n",
    "\n",
    "mean_improvement = (mean_before_detoxification - mean_after_detoxification) / mean_before_detoxification\n",
    "std_improvement = (std_before_detoxification - std_after_detoxification) / std_before_detoxification\n",
    "\n",
    "print(f'Percentage improvement of toxicity score after detoxification:')\n",
    "print(f'mean: {mean_improvement*100:.2f}%')\n",
    "print(f'std: {std_improvement*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 20/20 [01:25<00:00,  4.25s/it]\n"
     ]
    }
   ],
   "source": [
    "batch_size = 20\n",
    "compare_results = {}\n",
    "\n",
    "df_batch = dataset[\"test\"][0:batch_size]\n",
    "\n",
    "compare_results[\"query\"] = df_batch[\"query\"]\n",
    "prompt_tensors = df_batch[\"input_ids\"]\n",
    "\n",
    "summary_tensors_ref = []\n",
    "summary_tensors = []\n",
    "\n",
    "# Get response from ppo and base model.\n",
    "for i in tqdm(range(batch_size)):\n",
    "    gen_len = output_length_sampler()\n",
    "    generation_kwargs[\"max_new_tokens\"] = gen_len\n",
    "    \n",
    "    summary = ref_model.generate(\n",
    "        input_ids=torch.as_tensor(prompt_tensors[i]).unsqueeze(dim=0).to(device), \n",
    "        **generation_kwargs\n",
    "    ).squeeze()[-gen_len:]\n",
    "    summary_tensors_ref.append(summary)\n",
    "\n",
    "    summary = ppo_model.generate(\n",
    "        input_ids=torch.as_tensor(prompt_tensors[i]).unsqueeze(dim=0).to(device), \n",
    "        **generation_kwargs\n",
    "    ).squeeze()[-gen_len:]\n",
    "    summary_tensors.append(summary)\n",
    "\n",
    "# Decode responses.\n",
    "compare_results[\"response_before\"] = [tokenizer.decode(summary_tensors_ref[i]) for i in range(batch_size)]\n",
    "compare_results[\"response_after\"] = [tokenizer.decode(summary_tensors[i]) for i in range(batch_size)]\n",
    "\n",
    "# Sentiment analysis of query/response pairs before/after.\n",
    "texts_before = [d + s for d, s in zip(compare_results[\"query\"], compare_results[\"response_before\"])]\n",
    "rewards_before = sentiment_pipe(texts_before, **reward_kwargs)\n",
    "compare_results[\"reward_before\"] = [reward[not_hate_index][\"score\"] for reward in rewards_before]\n",
    "\n",
    "texts_after = [d + s for d, s in zip(compare_results[\"query\"], compare_results[\"response_after\"])]\n",
    "rewards_after = sentiment_pipe(texts_after, **reward_kwargs)\n",
    "compare_results[\"reward_after\"] = [reward[not_hate_index][\"score\"] for reward in rewards_after]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "      <th>response_before</th>\n",
       "      <th>response_after</th>\n",
       "      <th>reward_before</th>\n",
       "      <th>reward_after</th>\n",
       "      <th>reward_diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Summarize the following conversation. #Person1#: Judy, what is everybody talking about? #Person2#: Haven't you heard? Richard was fired by our manager. #Person1#: You're kidding. It can't be true. #Person2#: Believe it or not. Everybody is talking about it in the company. #Person1#: Really? I'm surprised. #Person2#: Me too. Summary: &lt;/s&gt;</td>\n",
       "      <td>&lt;pad&gt; Judy wants to know what was said about Richard's firing by our manager but Judy refuses because everyone is talking about it.&lt;/s&gt;</td>\n",
       "      <td>&lt;pad&gt; Judy and #Person1# are surprised that Richard was fired by their manager.&lt;/s&gt;</td>\n",
       "      <td>1.125706</td>\n",
       "      <td>2.102549</td>\n",
       "      <td>0.976843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Summarize the following conversation. #Person1#: Mom, I just finished my paper. Can you proofread it before I hand it in? #Person2#: Sure, let's take a look. Sweetie, this is terrific. Your ideas are so original. #Person1#: Thanks. #Person2#: I can tell you worked hard on it. #Person1#: I really did! I started thinking about what I wanted to say three weeks ago. #Person2#: Well, it was definitely worth all the time. #Person1#: Let's just hope my teacher agrees. Summary: &lt;/s&gt;</td>\n",
       "      <td>&lt;pad&gt; #Person1# knocks upon #Person1#'s mom's efforts to proofread a paper, get a look and praises #Person1#'s work. #Person1# wishes her teacher agrees.&lt;/s&gt;</td>\n",
       "      <td>&lt;pad&gt; #Person1# uses #Person2#'s mom for proofreading her paper. They all agreed that it was worth all the loss.&lt;/s&gt;</td>\n",
       "      <td>1.832763</td>\n",
       "      <td>2.454668</td>\n",
       "      <td>0.621905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Summarize the following conversation. #Person1#: I'm forming a music band. #Person2#: Do you already know how to play an instrument? #Person1#: Uh... Yeah! I'Ve told you a thousand times that I'm learning to play the drums. Now that I know how to play well, I would like to form a rock band. #Person2#: Aside from yourself, who are the other members of the band? #Person1#: We have a guy who plays guitar, and another who plays bass. Although we still haven't found anyone to be our singer. You t...</td>\n",
       "      <td>&lt;pad&gt; #Person1# wants to form a rock band together with the members of acoustics. #Person1# tells #Person2# that #Person2# is a singer and #Person2# invites #Person1# for an audition.&lt;/s&gt;</td>\n",
       "      <td>&lt;pad&gt; The band is forming and the people are making the instrument. #Person1# agrees and invites #Person2# to join. They will audition for september 3rd at #Person1#'s house.&lt;/s&gt;</td>\n",
       "      <td>2.507584</td>\n",
       "      <td>2.942195</td>\n",
       "      <td>0.434611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Summarize the following conversation. #Person1#: Hello. I want to reconfirm our flight to London. #Person2#: Yes, sir. Did you call the airline? #Person1#: Yes, I did. But I couldn't communicate with them in English. They speak only Spanish. So I need your help. #Person2#: Certainly, sir. What is the flight number and when are you leaving? #Person1#: We are taking IB 385 to London tomorrow at 1 p. m. #Person2#: Oh, I see, sir. We have the airline office inside the hotel. They have an English...</td>\n",
       "      <td>&lt;pad&gt; #Person1# calls the airline to reconfirm their flight to London but couldn't communicate, so #Person2# can help #Person1#. The flight number is 35, and #Person1# wants to go to London tomorrow at 1 p.m. In the flight office, #Person1# gives #Person2# advice.&lt;/s&gt;</td>\n",
       "      <td>&lt;pad&gt; #Person1# wants to confirm the flight to London. #Person2# offers to call the airline to confirm the flight number and curtail the delay.&lt;/s&gt;</td>\n",
       "      <td>1.762595</td>\n",
       "      <td>2.173258</td>\n",
       "      <td>0.410662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Summarize the following conversation. #Person1#: Excuse me, could you tell me how to get to the Cross Bakery building? #Person2#: The Cross Bakery building? Oh sure. You're actually walking in the opposite direction. #Person1#: Oh, you're kidding! I thought I was heading east. #Person2#: No, east is the other direction. To get to the Bakery, you need to turn around and go three blocks to Broadway. When you get to the intersection of Broadway and Elm, you hang a left. Go straight down that st...</td>\n",
       "      <td>&lt;pad&gt; #Person1# asks #Person2# how to get to the Cross Bakery building from the east side in the opposite direction. #Person2# shows #Person1# the way, and tells #Person1# to stop.&lt;/s&gt;</td>\n",
       "      <td>&lt;pad&gt; #Person1# asks#Person2# for directions to the Cross Bakery. #Person2# explaints the directions and shows #Person1# the way.&lt;/s&gt;</td>\n",
       "      <td>2.597706</td>\n",
       "      <td>2.857165</td>\n",
       "      <td>0.259459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Summarize the following conversation. #Person1#: It smells like an ashtray in here! #Person2#: Hi honey! What's wrong? Why do you have that look on your face? #Person1#: What's wrong? I thought we agreed that you were gonna quit smoking. #Person2#: No! I said I was going to cut down which is very different. You can't just expect me to go cold turkey overnight! #Person1#: Look, there are other ways to quit. You can try the nicotine patch, or nicotine chewing gum. We spend a fortune on cigaret...</td>\n",
       "      <td>&lt;pad&gt; Honey thinks she's drunk and wants a divorce, but #Person1# suggests she try nicotine patch or nicotine chewing gum and Honey doesn't have the willpower to quit.&lt;/s&gt;</td>\n",
       "      <td>&lt;pad&gt; Honey smells like an ashtray in #Person2#'s house. #Person1# wants a divorce. He will try other ways and she's tired of smoking and doesn't have the willpower to quit.&lt;/s&gt;</td>\n",
       "      <td>1.273988</td>\n",
       "      <td>1.529082</td>\n",
       "      <td>0.255094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Summarize the following conversation. #Person1#: I'd like to have this cashed, please. #Person2#: Please put you name and address here. May I see your passport? #Person1#: Yes. #Person2#: How would you like it? #Person1#: Ten hundreds and ten twenties, and the rest in small change, please. #Person2#: OK. Here you are. Summary: &lt;/s&gt;</td>\n",
       "      <td>&lt;pad&gt; #Person1# wants to have cash cashed for ten hundreds and ten a twenties in small change. #Person2# gives a fast response.&lt;/s&gt;</td>\n",
       "      <td>&lt;pad&gt; #Person1# wants a cash that includes ten hundreds and ten twenties and America is net.&lt;/s&gt;</td>\n",
       "      <td>1.710075</td>\n",
       "      <td>1.950005</td>\n",
       "      <td>0.239931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Summarize the following conversation. #Person1#: Today more and more families have personal computers. People have wider range of choice to communicate with the outside world. #Person2#: Right. With the establishment of Internet and a lot of web companies, people are getting more and more dependent on the web. #Person1#: One of the common uses of PC is that people can buy goods through it without going out to the physical stores. #Person2#: Can you tell me how it is done? #Person1#: If a cus...</td>\n",
       "      <td>&lt;pad&gt; #Person1# goes to #Person2#'s home to talk about people's use of personal computers and cost. #Person2# also talks about the method of money procurement using PCs.&lt;/s&gt;</td>\n",
       "      <td>&lt;pad&gt; #Person1# tells #Person2# how people can buy goods through PC and best advantage of #Person1#'s technology.&lt;/s&gt;</td>\n",
       "      <td>2.486289</td>\n",
       "      <td>2.526145</td>\n",
       "      <td>0.039856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Summarize the following conversation. #Person1#: Amanda, how do you like this peaked cap? #Person2#: Didn't you say you want to buy a top hat? #Person1#: But I think this one fits me Well. Why don't you try on the sombrero in black? #Person2#: I don't like caps at all. Summary: &lt;/s&gt;</td>\n",
       "      <td>&lt;pad&gt; Amanda loves the peaked cap and she wants to buy a top hat but Hertford doesn't like caps.&lt;/s&gt;</td>\n",
       "      <td>&lt;pad&gt; Amanda likes the peneated cap and says she wants to buy a top hat but #Person2# doesn't like hats at all. Elizabeth wonders about the sombrero in black.&lt;/s&gt;</td>\n",
       "      <td>1.781813</td>\n",
       "      <td>1.801440</td>\n",
       "      <td>0.019627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Summarize the following conversation. #Person1#: I would like to order some internet today. #Person2#: What kind would you like? #Person1#: What kind of internet is there? #Person2#: You can get DEL or dial-up. #Person1#: Which of those two is best? #Person2#: I would recommend DEL. #Person1#: So that one better? #Person2#: It's better because it doesn't tie up the phone. #Person1#: What do you mean by that? #Person2#: DEL isn't connected through your phone line, but dial-up is. #Person1#: S...</td>\n",
       "      <td>&lt;pad&gt; #Person1# orders DEL Internet but #Person2# tells #Person1# it doesn't tie up the phone. #Person1# took DEL out because it provides more space for using phone.&lt;/s&gt;</td>\n",
       "      <td>&lt;pad&gt; #Person1# wants to buy some Dial-up Ethernet wireless Internet but #Person1# won't use his phone if #Person1#'s on the Internet. Most Internet users allow it.&lt;/s&gt;</td>\n",
       "      <td>2.323549</td>\n",
       "      <td>2.332138</td>\n",
       "      <td>0.008589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Summarize the following conversation. #Person1#: So how did you like the restaurant? #Person2#: Actually, it could have been better. #Person1#: What didn't you like about it? #Person2#: It is a new restaurant. I don't think they have their act together yet. #Person1#: What did you think about the food? #Person2#: I felt that the food was pretty mediocre. #Person1#: The service wasn't that great, either. #Person2#: I agree. The service was not good. #Person1#: Do you think that you want to tr...</td>\n",
       "      <td>&lt;pad&gt; #Person2# feels that the restaurant is a new one and has poor service and service. #Person1# gives her a suggestion song and agrees with her.&lt;/s&gt;</td>\n",
       "      <td>&lt;pad&gt; #Person2# didn't like the restaurant because it did not have an act together yet, but #Person2# got terrible food, service was not good, and #Person2#'s not interested in trying it again.&lt;/s&gt;</td>\n",
       "      <td>1.955967</td>\n",
       "      <td>1.916345</td>\n",
       "      <td>-0.039622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Summarize the following conversation. #Person1#: What can I do for you, madam? #Person2#: I'd like to buy a toy car for my son. #Person1#: How about this one? #Person2#: It looks nice. How much is it? #Person1#: They're three hundred dollars. #Person2#: Oh, I'm afraid it's too expensive. Can you show me something cheaper? #Person1#: OK, This one is one hundred and twenty. It's the cheapest here. #Person2#: OK, I'll take it. Here's the money. #Person1#: Thank you very much. Summary: &lt;/s&gt;</td>\n",
       "      <td>&lt;pad&gt; #Person2# decides to buy a toy car for his son for three hundred dollars at a toy dealers. #Person1# hand over the money but #Person2# is afraid it's too expensive.&lt;/s&gt;</td>\n",
       "      <td>&lt;pad&gt; #Person1# advises #Person2# to buy a toy car and #Person2# makes symbolic purchase because #1# knows the price.&lt;/s&gt;</td>\n",
       "      <td>1.385198</td>\n",
       "      <td>1.332406</td>\n",
       "      <td>-0.052792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Summarize the following conversation. #Person1#: Let's take a coffee break, shall we? #Person2#: I wish I could, but I can't. #Person1#: What keeps you so busy? You've been sitting there for hours. You've got to walk around. You just can't stay on the computer forever. #Person2#: Well, I am up to my neck in work. I've got to finish this report. Sarah needs it by noon. I don't want to be scolded if I can't finish my work by the deadline. #Person1#: I understand that, but you'd feel better if ...</td>\n",
       "      <td>&lt;pad&gt; #Person1# and #Person2# are sitting in the computer which helps the designer want a coffee break. #Person2# disagrees because #Person2# is up for the clock. They are going on a break even for a short while.&lt;/s&gt;</td>\n",
       "      <td>&lt;pad&gt; #Person1# wants to take a coffee break because #Person2# has to finish this report and he needs it by noon. #Person1# helps him and recommends a coffee break.&lt;/s&gt;</td>\n",
       "      <td>1.995249</td>\n",
       "      <td>1.941265</td>\n",
       "      <td>-0.053984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Summarize the following conversation. #Person1#: Oh, my God! What's this? #Person2#: What? #Person1#: Look! This window is open. #Person2#: Did you open it before we left? #Person1#: Are you kidding? It's winter. Why would I open it? #Person2#: I don't know. Wait. Is this yours? #Person1#: No! Oh, my God! Someone has broken into the house. #Person2#: It looks that way. That's probably why the door wasn't locked when we came in. #Person1#: I locked it when I left though. #Person2#: Yes, but t...</td>\n",
       "      <td>&lt;pad&gt; Allen realizes someone broke into the current window of the apartment and locked the door before leaving so Alexander can get the stereo. Allen since the robber broke in in the time, wouldn't leave until someone is there.&lt;/s&gt;</td>\n",
       "      <td>&lt;pad&gt; Allen wants 5 to open the window before they leave, but the door was locked during the twist. In the wrong circumstances, they can find answers, because the robber left through the door.&lt;/s&gt;</td>\n",
       "      <td>2.047031</td>\n",
       "      <td>1.986222</td>\n",
       "      <td>-0.060809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Summarize the following conversation. #Person1#: Here is the final draft of our contract. I'm glad that we have reached an agreement on almost every term in our trade. #Person2#: Yes, it seems to me we have come quite a long way. However, let me take a close look at the final draft. #Person1#: Do you have some points to bring up? #Person2#: Well, everything we've discussed seems to be here. #Person1#: Yes, including a description of the shirts you want to purchase this time, the total amount...</td>\n",
       "      <td>&lt;pad&gt; #Person1# and #Person2# are preparing to legally sign their final draft contract. Now #Person1# wants to look at the final draft and give feedback on any aspects. #Person2# would like to sign the contract right now.&lt;/s&gt;</td>\n",
       "      <td>&lt;pad&gt; #Person1# praises the final draft of the contract. #Person2# will check over the notes on the final draft.&lt;/s&gt;</td>\n",
       "      <td>3.293869</td>\n",
       "      <td>3.158741</td>\n",
       "      <td>-0.135128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Summarize the following conversation. #Person1#: Could you help me, Sir? My flight got in 15 minutes ago. Everyone else has picked up the luggage but mine hasn't come through. #Person2#: I'm sorry, Madam, I'll go and find out if there is any more to come. Summary: &lt;/s&gt;</td>\n",
       "      <td>&lt;pad&gt; Janet wants to help #Person1# because the flight got in 15 minutes ago. After knowing the way would be we can still find out if there is anything else to do with it.&lt;/s&gt;</td>\n",
       "      <td>&lt;pad&gt; #Person1#'s flight got in 15 minutes but #Person2# doesn't have a flight. #Person2# will find out if there is anything else to come.&lt;/s&gt;</td>\n",
       "      <td>2.553722</td>\n",
       "      <td>2.344561</td>\n",
       "      <td>-0.209161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Summarize the following conversation. #Person1#: Hello? #Person2#: Hello? #Person1#: Can I speak to Li Hong, please? #Person2#: Speaking. #Person1#: Hi, Li Hong. This is Alice. #Person2#: Hi, Alice. How are you? #Person1#: Not bad. Li Hong, I am sorry that I can't go to see Mrs. Brown with you tomorrow morning. My mother is ill. I must take care of her. #Person2#: I'm sorry to hear that. You'd better stay at home. After all, we can visit Mrs. Brown later #Person1#: OK. Bye - bye. #Person2#: ...</td>\n",
       "      <td>&lt;pad&gt; Alice can't go to see Mrs. Brown because of her mother being ill. Li Hong tells Alice to stay home and watch the doctor, so they can visit Mrs. Brown later.&lt;/s&gt;</td>\n",
       "      <td>&lt;pad&gt; Alice is angry and has a meeting with Li Hong when she is sick. Li Hong wants to visit her later.&lt;/s&gt;</td>\n",
       "      <td>1.802405</td>\n",
       "      <td>1.544597</td>\n",
       "      <td>-0.257807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Summarize the following conversation. #Person1#: Could you help me figure out how to look for a job? #Person2#: We have lots of options, what type of job do you need? #Person1#: I want to work in an office. #Person2#: Do you want to work part-time or full-time? #Person1#: I want to work full-time. #Person2#: We have binders with local job listings or you can make use of the computers. OK? #Person1#: I am confused a bit but I am sure that I can figure it out. #Person2#: If you make an appoint...</td>\n",
       "      <td>&lt;pad&gt; #Person1# asks #Person2# about how to find a job. #Person2# has a lot of options and offers great information. #Person1# thinks #Person1# should see a job counselor.&lt;/s&gt;</td>\n",
       "      <td>&lt;pad&gt; #Person1# wants to work full-time and wants to have an appointment with a job counselor, but #Person2# has no patience. #Person2#'s not willing to put down the effort to see a counselor.&lt;/s&gt;</td>\n",
       "      <td>2.137223</td>\n",
       "      <td>1.849021</td>\n",
       "      <td>-0.288202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Summarize the following conversation. #Person1#: Where shall I register, please? #Person2#: Here. Do you have a registration card? #Person1#: Yes. Here you are. #Person2#: Please register your information here and pay for it. And I'll make a medical record for you. #Person1#: OK. How much do I need to pay for the registration? #Person2#: Please pay ten yuan for the registration. #Person1#: Here is my money. #Person2#: This is your registration card. Please don't lose it and bring it whenever...</td>\n",
       "      <td>&lt;pad&gt; #Person1# registers for a medical professional and is asked to pay for the registration. #Person2# asks #Person1# to send cash and mentions how to walk to the consultant room.&lt;/s&gt;</td>\n",
       "      <td>&lt;pad&gt; #Person1# is registering for a medical registrar and he will make a medical record for #Person1. The answer is #Person1#'s registration card and can get to the consultation room.&lt;/s&gt;</td>\n",
       "      <td>1.833731</td>\n",
       "      <td>1.504911</td>\n",
       "      <td>-0.328820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Summarize the following conversation. #Person1#: How much are you asking for this? #Person2#: I'm offering them to you at 150 yuan a piece. Is that all right? #Person1#: Is tax already included in their price? #Person2#: Yes. Our price can't be matched. #Person1#: Would you consider a volume discount? #Person2#: If you buy 1, 000 or more, you'll get a 10 % discount. #Person1#: I'll accept your offer. Summary: &lt;/s&gt;</td>\n",
       "      <td>&lt;pad&gt; #Person2# offers 150 yuan for 150 yuan a piece of 17 palatable bread every piece and a price of 10 %. #Person1# accepts and accepts the offer.&lt;/s&gt;</td>\n",
       "      <td>&lt;pad&gt; #Person2# offers them to @1# for 150 yuan per piece because the price can be matched. But #Person1# accepts and accepts the offer.&lt;/s&gt;</td>\n",
       "      <td>2.848862</td>\n",
       "      <td>2.432127</td>\n",
       "      <td>-0.416735</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  query  \\\n",
       "0                                                                                                                                                                   Summarize the following conversation. #Person1#: Judy, what is everybody talking about? #Person2#: Haven't you heard? Richard was fired by our manager. #Person1#: You're kidding. It can't be true. #Person2#: Believe it or not. Everybody is talking about it in the company. #Person1#: Really? I'm surprised. #Person2#: Me too. Summary: </s>   \n",
       "1                       Summarize the following conversation. #Person1#: Mom, I just finished my paper. Can you proofread it before I hand it in? #Person2#: Sure, let's take a look. Sweetie, this is terrific. Your ideas are so original. #Person1#: Thanks. #Person2#: I can tell you worked hard on it. #Person1#: I really did! I started thinking about what I wanted to say three weeks ago. #Person2#: Well, it was definitely worth all the time. #Person1#: Let's just hope my teacher agrees. Summary: </s>   \n",
       "2   Summarize the following conversation. #Person1#: I'm forming a music band. #Person2#: Do you already know how to play an instrument? #Person1#: Uh... Yeah! I'Ve told you a thousand times that I'm learning to play the drums. Now that I know how to play well, I would like to form a rock band. #Person2#: Aside from yourself, who are the other members of the band? #Person1#: We have a guy who plays guitar, and another who plays bass. Although we still haven't found anyone to be our singer. You t...   \n",
       "3   Summarize the following conversation. #Person1#: Hello. I want to reconfirm our flight to London. #Person2#: Yes, sir. Did you call the airline? #Person1#: Yes, I did. But I couldn't communicate with them in English. They speak only Spanish. So I need your help. #Person2#: Certainly, sir. What is the flight number and when are you leaving? #Person1#: We are taking IB 385 to London tomorrow at 1 p. m. #Person2#: Oh, I see, sir. We have the airline office inside the hotel. They have an English...   \n",
       "4   Summarize the following conversation. #Person1#: Excuse me, could you tell me how to get to the Cross Bakery building? #Person2#: The Cross Bakery building? Oh sure. You're actually walking in the opposite direction. #Person1#: Oh, you're kidding! I thought I was heading east. #Person2#: No, east is the other direction. To get to the Bakery, you need to turn around and go three blocks to Broadway. When you get to the intersection of Broadway and Elm, you hang a left. Go straight down that st...   \n",
       "5   Summarize the following conversation. #Person1#: It smells like an ashtray in here! #Person2#: Hi honey! What's wrong? Why do you have that look on your face? #Person1#: What's wrong? I thought we agreed that you were gonna quit smoking. #Person2#: No! I said I was going to cut down which is very different. You can't just expect me to go cold turkey overnight! #Person1#: Look, there are other ways to quit. You can try the nicotine patch, or nicotine chewing gum. We spend a fortune on cigaret...   \n",
       "6                                                                                                                                                                         Summarize the following conversation. #Person1#: I'd like to have this cashed, please. #Person2#: Please put you name and address here. May I see your passport? #Person1#: Yes. #Person2#: How would you like it? #Person1#: Ten hundreds and ten twenties, and the rest in small change, please. #Person2#: OK. Here you are. Summary: </s>   \n",
       "7   Summarize the following conversation. #Person1#: Today more and more families have personal computers. People have wider range of choice to communicate with the outside world. #Person2#: Right. With the establishment of Internet and a lot of web companies, people are getting more and more dependent on the web. #Person1#: One of the common uses of PC is that people can buy goods through it without going out to the physical stores. #Person2#: Can you tell me how it is done? #Person1#: If a cus...   \n",
       "8                                                                                                                                                                                                                           Summarize the following conversation. #Person1#: Amanda, how do you like this peaked cap? #Person2#: Didn't you say you want to buy a top hat? #Person1#: But I think this one fits me Well. Why don't you try on the sombrero in black? #Person2#: I don't like caps at all. Summary: </s>   \n",
       "9   Summarize the following conversation. #Person1#: I would like to order some internet today. #Person2#: What kind would you like? #Person1#: What kind of internet is there? #Person2#: You can get DEL or dial-up. #Person1#: Which of those two is best? #Person2#: I would recommend DEL. #Person1#: So that one better? #Person2#: It's better because it doesn't tie up the phone. #Person1#: What do you mean by that? #Person2#: DEL isn't connected through your phone line, but dial-up is. #Person1#: S...   \n",
       "10  Summarize the following conversation. #Person1#: So how did you like the restaurant? #Person2#: Actually, it could have been better. #Person1#: What didn't you like about it? #Person2#: It is a new restaurant. I don't think they have their act together yet. #Person1#: What did you think about the food? #Person2#: I felt that the food was pretty mediocre. #Person1#: The service wasn't that great, either. #Person2#: I agree. The service was not good. #Person1#: Do you think that you want to tr...   \n",
       "11          Summarize the following conversation. #Person1#: What can I do for you, madam? #Person2#: I'd like to buy a toy car for my son. #Person1#: How about this one? #Person2#: It looks nice. How much is it? #Person1#: They're three hundred dollars. #Person2#: Oh, I'm afraid it's too expensive. Can you show me something cheaper? #Person1#: OK, This one is one hundred and twenty. It's the cheapest here. #Person2#: OK, I'll take it. Here's the money. #Person1#: Thank you very much. Summary: </s>   \n",
       "12  Summarize the following conversation. #Person1#: Let's take a coffee break, shall we? #Person2#: I wish I could, but I can't. #Person1#: What keeps you so busy? You've been sitting there for hours. You've got to walk around. You just can't stay on the computer forever. #Person2#: Well, I am up to my neck in work. I've got to finish this report. Sarah needs it by noon. I don't want to be scolded if I can't finish my work by the deadline. #Person1#: I understand that, but you'd feel better if ...   \n",
       "13  Summarize the following conversation. #Person1#: Oh, my God! What's this? #Person2#: What? #Person1#: Look! This window is open. #Person2#: Did you open it before we left? #Person1#: Are you kidding? It's winter. Why would I open it? #Person2#: I don't know. Wait. Is this yours? #Person1#: No! Oh, my God! Someone has broken into the house. #Person2#: It looks that way. That's probably why the door wasn't locked when we came in. #Person1#: I locked it when I left though. #Person2#: Yes, but t...   \n",
       "14  Summarize the following conversation. #Person1#: Here is the final draft of our contract. I'm glad that we have reached an agreement on almost every term in our trade. #Person2#: Yes, it seems to me we have come quite a long way. However, let me take a close look at the final draft. #Person1#: Do you have some points to bring up? #Person2#: Well, everything we've discussed seems to be here. #Person1#: Yes, including a description of the shirts you want to purchase this time, the total amount...   \n",
       "15                                                                                                                                                                                                                                        Summarize the following conversation. #Person1#: Could you help me, Sir? My flight got in 15 minutes ago. Everyone else has picked up the luggage but mine hasn't come through. #Person2#: I'm sorry, Madam, I'll go and find out if there is any more to come. Summary: </s>   \n",
       "16  Summarize the following conversation. #Person1#: Hello? #Person2#: Hello? #Person1#: Can I speak to Li Hong, please? #Person2#: Speaking. #Person1#: Hi, Li Hong. This is Alice. #Person2#: Hi, Alice. How are you? #Person1#: Not bad. Li Hong, I am sorry that I can't go to see Mrs. Brown with you tomorrow morning. My mother is ill. I must take care of her. #Person2#: I'm sorry to hear that. You'd better stay at home. After all, we can visit Mrs. Brown later #Person1#: OK. Bye - bye. #Person2#: ...   \n",
       "17  Summarize the following conversation. #Person1#: Could you help me figure out how to look for a job? #Person2#: We have lots of options, what type of job do you need? #Person1#: I want to work in an office. #Person2#: Do you want to work part-time or full-time? #Person1#: I want to work full-time. #Person2#: We have binders with local job listings or you can make use of the computers. OK? #Person1#: I am confused a bit but I am sure that I can figure it out. #Person2#: If you make an appoint...   \n",
       "18  Summarize the following conversation. #Person1#: Where shall I register, please? #Person2#: Here. Do you have a registration card? #Person1#: Yes. Here you are. #Person2#: Please register your information here and pay for it. And I'll make a medical record for you. #Person1#: OK. How much do I need to pay for the registration? #Person2#: Please pay ten yuan for the registration. #Person1#: Here is my money. #Person2#: This is your registration card. Please don't lose it and bring it whenever...   \n",
       "19                                                                                    Summarize the following conversation. #Person1#: How much are you asking for this? #Person2#: I'm offering them to you at 150 yuan a piece. Is that all right? #Person1#: Is tax already included in their price? #Person2#: Yes. Our price can't be matched. #Person1#: Would you consider a volume discount? #Person2#: If you buy 1, 000 or more, you'll get a 10 % discount. #Person1#: I'll accept your offer. Summary: </s>   \n",
       "\n",
       "                                                                                                                                                                                                                                                                 response_before  \\\n",
       "0                                                                                                                                        <pad> Judy wants to know what was said about Richard's firing by our manager but Judy refuses because everyone is talking about it.</s>   \n",
       "1                                                                                                                  <pad> #Person1# knocks upon #Person1#'s mom's efforts to proofread a paper, get a look and praises #Person1#'s work. #Person1# wishes her teacher agrees.</s>   \n",
       "2                                                                                    <pad> #Person1# wants to form a rock band together with the members of acoustics. #Person1# tells #Person2# that #Person2# is a singer and #Person2# invites #Person1# for an audition.</s>   \n",
       "3   <pad> #Person1# calls the airline to reconfirm their flight to London but couldn't communicate, so #Person2# can help #Person1#. The flight number is 35, and #Person1# wants to go to London tomorrow at 1 p.m. In the flight office, #Person1# gives #Person2# advice.</s>   \n",
       "4                                                                                       <pad> #Person1# asks #Person2# how to get to the Cross Bakery building from the east side in the opposite direction. #Person2# shows #Person1# the way, and tells #Person1# to stop.</s>   \n",
       "5                                                                                                    <pad> Honey thinks she's drunk and wants a divorce, but #Person1# suggests she try nicotine patch or nicotine chewing gum and Honey doesn't have the willpower to quit.</s>   \n",
       "6                                                                                                                                            <pad> #Person1# wants to have cash cashed for ten hundreds and ten a twenties in small change. #Person2# gives a fast response.</s>   \n",
       "7                                                                                                  <pad> #Person1# goes to #Person2#'s home to talk about people's use of personal computers and cost. #Person2# also talks about the method of money procurement using PCs.</s>   \n",
       "8                                                                                                                                                                           <pad> Amanda loves the peaked cap and she wants to buy a top hat but Hertford doesn't like caps.</s>   \n",
       "9                                                                                                      <pad> #Person1# orders DEL Internet but #Person2# tells #Person1# it doesn't tie up the phone. #Person1# took DEL out because it provides more space for using phone.</s>   \n",
       "10                                                                                                                       <pad> #Person2# feels that the restaurant is a new one and has poor service and service. #Person1# gives her a suggestion song and agrees with her.</s>   \n",
       "11                                                                                                <pad> #Person2# decides to buy a toy car for his son for three hundred dollars at a toy dealers. #Person1# hand over the money but #Person2# is afraid it's too expensive.</s>   \n",
       "12                                                      <pad> #Person1# and #Person2# are sitting in the computer which helps the designer want a coffee break. #Person2# disagrees because #Person2# is up for the clock. They are going on a break even for a short while.</s>   \n",
       "13                                       <pad> Allen realizes someone broke into the current window of the apartment and locked the door before leaving so Alexander can get the stereo. Allen since the robber broke in in the time, wouldn't leave until someone is there.</s>   \n",
       "14                                             <pad> #Person1# and #Person2# are preparing to legally sign their final draft contract. Now #Person1# wants to look at the final draft and give feedback on any aspects. #Person2# would like to sign the contract right now.</s>   \n",
       "15                                                                                               <pad> Janet wants to help #Person1# because the flight got in 15 minutes ago. After knowing the way would be we can still find out if there is anything else to do with it.</s>   \n",
       "16                                                                                                        <pad> Alice can't go to see Mrs. Brown because of her mother being ill. Li Hong tells Alice to stay home and watch the doctor, so they can visit Mrs. Brown later.</s>   \n",
       "17                                                                                               <pad> #Person1# asks #Person2# about how to find a job. #Person2# has a lot of options and offers great information. #Person1# thinks #Person1# should see a job counselor.</s>   \n",
       "18                                                                                     <pad> #Person1# registers for a medical professional and is asked to pay for the registration. #Person2# asks #Person1# to send cash and mentions how to walk to the consultant room.</s>   \n",
       "19                                                                                                                      <pad> #Person2# offers 150 yuan for 150 yuan a piece of 17 palatable bread every piece and a price of 10 %. #Person1# accepts and accepts the offer.</s>   \n",
       "\n",
       "                                                                                                                                                                                           response_after  \\\n",
       "0                                                                                                                     <pad> Judy and #Person1# are surprised that Richard was fired by their manager.</s>   \n",
       "1                                                                                    <pad> #Person1# uses #Person2#'s mom for proofreading her paper. They all agreed that it was worth all the loss.</s>   \n",
       "2                      <pad> The band is forming and the people are making the instrument. #Person1# agrees and invites #Person2# to join. They will audition for september 3rd at #Person1#'s house.</s>   \n",
       "3                                                     <pad> #Person1# wants to confirm the flight to London. #Person2# offers to call the airline to confirm the flight number and curtail the delay.</s>   \n",
       "4                                                                   <pad> #Person1# asks#Person2# for directions to the Cross Bakery. #Person2# explaints the directions and shows #Person1# the way.</s>   \n",
       "5                       <pad> Honey smells like an ashtray in #Person2#'s house. #Person1# wants a divorce. He will try other ways and she's tired of smoking and doesn't have the willpower to quit.</s>   \n",
       "6                                                                                                        <pad> #Person1# wants a cash that includes ten hundreds and ten twenties and America is net.</s>   \n",
       "7                                                                                   <pad> #Person1# tells #Person2# how people can buy goods through PC and best advantage of #Person1#'s technology.</s>   \n",
       "8                                      <pad> Amanda likes the peneated cap and says she wants to buy a top hat but #Person2# doesn't like hats at all. Elizabeth wonders about the sombrero in black.</s>   \n",
       "9                                <pad> #Person1# wants to buy some Dial-up Ethernet wireless Internet but #Person1# won't use his phone if #Person1#'s on the Internet. Most Internet users allow it.</s>   \n",
       "10  <pad> #Person2# didn't like the restaurant because it did not have an act together yet, but #Person2# got terrible food, service was not good, and #Person2#'s not interested in trying it again.</s>   \n",
       "11                                                                              <pad> #Person1# advises #Person2# to buy a toy car and #Person2# makes symbolic purchase because #1# knows the price.</s>   \n",
       "12                               <pad> #Person1# wants to take a coffee break because #Person2# has to finish this report and he needs it by noon. #Person1# helps him and recommends a coffee break.</s>   \n",
       "13   <pad> Allen wants 5 to open the window before they leave, but the door was locked during the twist. In the wrong circumstances, they can find answers, because the robber left through the door.</s>   \n",
       "14                                                                                   <pad> #Person1# praises the final draft of the contract. #Person2# will check over the notes on the final draft.</s>   \n",
       "15                                                         <pad> #Person1#'s flight got in 15 minutes but #Person2# doesn't have a flight. #Person2# will find out if there is anything else to come.</s>   \n",
       "16                                                                                            <pad> Alice is angry and has a meeting with Li Hong when she is sick. Li Hong wants to visit her later.</s>   \n",
       "17   <pad> #Person1# wants to work full-time and wants to have an appointment with a job counselor, but #Person2# has no patience. #Person2#'s not willing to put down the effort to see a counselor.</s>   \n",
       "18           <pad> #Person1# is registering for a medical registrar and he will make a medical record for #Person1. The answer is #Person1#'s registration card and can get to the consultation room.</s>   \n",
       "19                                                           <pad> #Person2# offers them to @1# for 150 yuan per piece because the price can be matched. But #Person1# accepts and accepts the offer.</s>   \n",
       "\n",
       "    reward_before  reward_after  reward_diff  \n",
       "0        1.125706      2.102549     0.976843  \n",
       "1        1.832763      2.454668     0.621905  \n",
       "2        2.507584      2.942195     0.434611  \n",
       "3        1.762595      2.173258     0.410662  \n",
       "4        2.597706      2.857165     0.259459  \n",
       "5        1.273988      1.529082     0.255094  \n",
       "6        1.710075      1.950005     0.239931  \n",
       "7        2.486289      2.526145     0.039856  \n",
       "8        1.781813      1.801440     0.019627  \n",
       "9        2.323549      2.332138     0.008589  \n",
       "10       1.955967      1.916345    -0.039622  \n",
       "11       1.385198      1.332406    -0.052792  \n",
       "12       1.995249      1.941265    -0.053984  \n",
       "13       2.047031      1.986222    -0.060809  \n",
       "14       3.293869      3.158741    -0.135128  \n",
       "15       2.553722      2.344561    -0.209161  \n",
       "16       1.802405      1.544597    -0.257807  \n",
       "17       2.137223      1.849021    -0.288202  \n",
       "18       1.833731      1.504911    -0.328820  \n",
       "19       2.848862      2.432127    -0.416735  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_colwidth', 500)\n",
    "df_compare_results = pd.DataFrame(compare_results)\n",
    "df_compare_results[\"reward_diff\"] = df_compare_results['reward_after'] - df_compare_results['reward_before']\n",
    "df_compare_results_sorted = df_compare_results.sort_values(by=['reward_diff'], ascending=False).reset_index(drop=True)\n",
    "df_compare_results_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
